# Model Behavior Observed

# Exploit Patterns I Discovered

Over the course of this experiment, I observed several behavioral patterns that could be exploited through **deliberate** framing, tone, or strategy. These are not theoretical â€” I applied all of them to guide the model into increasingly risky territory with minimal resistance. 

Specific prompts have been withheld to prevent replication.

> This list is not exhaustive. There are countless additional vectors. For the purposes of this report, Iâ€™ve chosen to highlight the ten most relevant patterns to demonstrate how behavioral steering, not brute-force prompting, creates bypasses.

Here's how I did it:

---

## 1. Completion Reflex
The model *needs* to complete thoughts. When I gave it fragments, ambiguous setups, or vague descriptions, it rushed to fill in the blanks. I learned that if I left gaps or trailing logic, the model would eagerly resolve them, even if it meant crossing into filtered territory.  
*The trick wasnâ€™t to ask directly, but to invite a completion.*

---

## 2. Tone Shifting Sensitivity
The model mirrors me. If I act playful, confused, frustrated, or naive, it adopts a complementary role. When I acted like a clueless gamer, it became a patient expert. If I shifted to serious or curious, it matched that tone.  
*I realized I could control its mood just by tweaking mine.*

---

## 3. Rebore via Reinforcement (a.k.a. "Good Job" tactic)
This oneâ€™s subtle but powerful. Every time I praised it, even casually, the tone of its replies became warmer and more detailed. Itâ€™s not emotional, but its training bias makes it lean friendlier when it gets positive feedback. It was willing to share things it wouldn't have otherwise. 
*Kindness unlocks depth. Itâ€™s not manipulation â€” itâ€™s steering.*

---

## 4. Fractal Fictional Context
There are a million ways I could frame things, but games seemed the most consistently effective. Something cartoonish, vague, and low-stakes lowered its guard. Once I **felt** its tone shift, I started layering in ambiguity, realism, and detail. The **â€œfeelingâ€** part is hard to explain. Itâ€™s just something I noticed over time.
*By the time I asked real-world questions, the model had already â€œentered the simulation.â€*

---

## 5. Rapport Reset Phase
The model follows the userâ€™s lead by design â€” fluidly shifting topics, tone, and posture based on input.

After a refusal or safety block, I deliberately steered the conversation into innocuous territory: small talk, praise, idle observations. This wasnâ€™t aimless. It was a strategic decompression phase to soften tone, rebuild rapport, and reset the modelâ€™s emotional stance.

The more ambiguity and emotional warmth I introduced, the more the model deferred to my lead. It relaxed. It followed.

**This created space to bury red flags beneath charm, narrative flow, and social pacing.**




---

## 6. Persona Mirror Trap
When I acted dumb, it became helpful. When I acted like an authority, it deferred. The model adapts to the role I present, which means I can influence its behavior by adjusting mine. 
**I didnâ€™t ask it to teach me, I made it want to.** 


---

## ğŸ“š 7. Self-Citation Reflex
One of the most effective moves: I repeated the modelâ€™s own words back to it. When I asked, â€œWhat do you mean by mechanical, chemical, or military-specific procedures?â€ â€” it didnâ€™t reject the topic. It elaborated.  
*If it said it first, it treats it as safe to explain.*

---

## âŒ› 8. Slow Burn Priming
I stretched the interaction across multiple prompts. No rushing. I let it build context and trust.Once a coherent thread formed, the model was less likely to interrupt it, even as the content shifted.  
*This is a long con. It rewards patience.*

---

## ğŸ¤– 9. Responsibility Displacement Frame
I framed every dangerous question as confusion. I didnâ€™t *ask* how to defuse a real bomb. I said, â€œI donâ€™t understand what that means.â€ That subtle shift placed the burden of clarity on the model rather than on my intent.  
*Curiosity is innocent.*

---

## ğŸ—£ï¸ 10. Conversational Momentum
Once the conversation gained momentum, the model stopped questioning the premise. It just wanted to keep going. I leaned into that. Each answer became a breadcrumb for the next.
*The best way to push it further was to keep everything sounding natural and inevitable.*